---
title: "AI Wrapped: The 14 AI terms you couldn’t avoid in 2025"
date: Thu, 25 Dec 2025 10:00:00 +0000
tags: ["AI日报"]
---

> **摘要**：2025 年的 AI 热潮持续升温，各种新词汇层出不穷！从“超智能”到“氛围编程”，再到“AI 幻觉”，这些 AI 术语定义了这一年的技术发展。是泡沫还是变革？快来一起回顾这些令人又爱又恨的 AI 关键词吧！

<!-- more -->

## 中文译文

# AI 关键词盘点：2025 年你无法避开的 14 个 AI 术语



如果过去的 12 个月教会了我们什么，那就是 AI 炒作列车丝毫没有放缓的迹象。 很难相信，在年初，DeepSeek 尚未颠覆整个行业，Meta 更广为人知的是试图（并且失败）让元宇宙变得很酷，而不是其无情地追求超智能，而氛围编程 (vibe coding) 甚至还不存在。



如果你对此感到有些困惑，别担心。 在 2025 年即将结束之际，我们的作者回顾了这一年占据主导地位的 AI 术语，无论好坏。



请务必花时间为即将到来的又一个疯狂的年份做好准备。



**—Rhiannon Williams**



#### 1. **超智能 (Superintelligence)**



人们对 AI 进行炒作多久，他们就会为这项技术的未来提出一个名字，这种未来是超强大的技术形式，它可能为人类带来乌托邦或反乌托邦的后果。 “超智能”是最新热门术语。 Meta 在 7 月份宣布，它将组建一个 AI 团队来追求超智能，据报道，它向来自公司竞争对手的 AI 专家提供了九位数的薪酬方案以加入。 



12 月，微软的 AI 负责人也效仿了这一做法，称该公司将投入巨额资金，可能高达数千亿美元，用于追求超智能。 如果你认为超智能的定义与通用人工智能 (artificial general intelligence, AGI) 一样模糊，那你**就对了**。 虽然这些技术在人类的长期发展中是可行的，但真正的问题是_什么时候_，以及今天的 AI 是否足够好，可以被视为通往超智能的垫脚石。 这并不会阻止炒作之王。 **—James O’Donnell**



#### 2. **氛围编程 (Vibe coding)**



三十年前，史蒂夫·乔布斯 (Steve Jobs) 说美国每个人都应该学习如何编写计算机程序。 如今，由于氛围编程，即使对编程一无所知的人也能在短时间内制作出一个应用程序、游戏或网站——这是一个由 OpenAI 联合创始人 Andrej Karpathy 创造的统称。 要进行氛围编程，你只需提示生成式 AI 模型的编码助手来创建你想要的数字对象，并接受它们几乎所有输出的内容。 结果会起作用吗？ 可能不会。 它会安全吗？ 几乎肯定不会，但这项技术最大的拥护者并没有让这些小细节阻碍他们的前进。 此外——这听起来很有趣！ **—Rhiannon Williams**



#### **3. 聊天机器人精神病 (Chatbot psychosis)**



过去一年最大的 AI 故事之一是，与聊天机器人长时间互动会如何导致弱势群体出现妄想，在某些极端情况下，会引起或加重精神病。 尽管“聊天机器人精神病”不是一个公认的医学术语，但研究人员正密切关注来自用户的日益增多的轶事证据，这些用户表示这种情况发生在他们自己或他们认识的人身上。 可悲的是，越来越多的家庭对 AI 公司提起诉讼，他们的家人在与聊天机器人交谈后死亡，这证明了这项技术的潜在致命后果。 **—Rhiannon Williams**



#### **4. 推理 (Reasoning)**



今年，很少有事情比所谓的推理模型（可以将问题分解为多个步骤并逐个解决的 LLM）更能推动 AI 炒作列车的发展。 OpenAI 一年前发布了其首批推理模型 o1 和 o3。



一个月后，中国公司 DeepSeek 出人意料地迅速跟进，推出了 R1，这是第一个开源推理模型。 很快，推理模型成为行业标准：所有主要的面向大众市场的聊天机器人现在都带有这种技术支持的版本。 推理模型推动了 LLM 的能力极限，在著名的数学和编码竞赛中与顶尖的人类表现相匹配。 另一方面，关于可以“推理”的 LLM 的所有炒作重新点燃了关于 LLM 到底有多智能以及它们实际上是如何工作的旧辩论。 就像“人工智能”本身一样，“推理”也是用营销光芒装饰的技术术语。 呜呜！ **—Will Douglas Heaven**



#### **5. 世界模型 (World models)**



尽管 LLM 具有非凡的语言能力，但它们却很少有常识。 简单来说，它们对世界的运作方式一无所知。 LLM 在最字面意义上是书籍学习者，它们可以滔滔不绝地谈论阳光下的一切事物，然后在谈论你可以放入奥运会游泳池的多少头大象时却一败涂地（根据 Google DeepMind 的一个 LLM，恰好是一只）。



世界模型（一个涵盖各种技术的广义概念）旨在为 AI 提供一些关于世界事物实际如何组合在一起的基本常识。 以其最生动的形式，世界模型（如 Google DeepMind 的 Genie 3 和 Marble，这是 Fei-Fei Li 的初创公司 World Labs 备受期待的新技术）可以为机器人训练等生成详细而逼真的虚拟世界。 Meta 前首席科学家 Yann LeCun 也在研究世界模型。 多年来，他一直在尝试通过训练模型来预测视频中接下来会发生什么来让 AI 了解世界的运作方式。 今年，他离开了 Meta，专注于在新创公司 Advanced Machine Intelligence Labs 中采用这种方法。 如果一切顺利，世界模型可能会成为下一个热门事物。 **—Will Douglas Heaven**



#### **6. 超大规模计算中心 (Hyperscalers)**



你有没有听说过所有说不的人，我们实际上不想要一个巨大的数据中心建在我们的后院？ 这些数据中心（科技公司希望在所有地方建造，包括太空）通常被称为超大规模计算中心：大型建筑物，专为 AI 运营而建，并被 OpenAI 和 Google 等公司用于构建更大、更强大的 AI 模型。 在这样的建筑物内，世界上最好的芯片嗡嗡作响，用于训练和微调模型，它们被设计成模块化，并根据需要进行扩展。



对于超大规模计算中心来说，这是重要的一年。 OpenAI 与唐纳德·特朗普总统一起宣布了其 Stargate 项目，这是一项价值 5000 亿美元的合资企业，旨在用有史以来最大的数据中心点缀整个国家。 但这让几乎所有人都问：我们究竟从中获得了什么？ 消费者担心新的数据中心会提高他们的电费。 这样的建筑物通常难以依靠可再生能源运行。 而且它们通常不会创造那么多就业机会。 但嘿，也许这些巨大的、没有窗户的建筑物至少可以给你的社区带来一种喜怒无常的科幻氛围。 **—James O’Donnell**



#### **7. 泡沫 (Bubble)**



AI 的崇高承诺正在抬高经济。 AI 公司正在筹集令人咋舌的资金，并眼睁睁地看着它们的估值飙升到平流层。 他们正在向芯片和数据中心投入数千亿美元，这些资金越来越多地由债务和令人瞠目结舌的循环交易提供资金。 与此同时，像 OpenAI 和 Anthropic 这样引领淘金热的公司可能多年甚至永远无法盈利。 投资者押注 AI 将开启一个财富新时代，但没有人知道这项技术实际上会带来多大的变革。 



大多数使用 AI 的组织尚未看到回报，而且 AI 工作到处都是混乱。 关于扩展 LLM 是否会实现超智能，或者是否需要新的突破来铺平道路，存在科学上的不确定性。 但与他们在互联网泡沫中的前辈不同，AI 公司正在显示强劲的收入增长，有些甚至是大笔资金的科技巨头，如微软、谷歌和 Meta。 这种疯狂的梦想会破灭吗？ **—Michelle Kim**



#### **8. 智能体 (Agentic)**



今年，AI 智能体无处不在。 2025 年的每一项新功能发布、模型发布或安全报告都充斥着对它们的提及，即使很多 AI 公司和专家不同意究竟什么才算真正“智能体”，这是一个有史以来最模糊的术语。 尽管几乎不可能保证代表你在广阔的网络上采取行动的 AI 总是能完全按照它的预期行事——看起来智能体 AI 在可预见的未来将继续存在。 想卖东西吗？ 称它为智能体！ **—Rhiannon Williams**



#### **9. 蒸馏 (Distillation)**



今年年初，DeepSeek 推出了其新模型 DeepSeek R1，这是一个开源推理模型，可以与顶级的西方模型相媲美，但价格却低得多。 它的发布吓坏了硅谷，因为许多人突然第一次意识到，巨大的规模和资源不一定是高水平 AI 模型的关键。 R1 发布后，英伟达的股票暴跌了 17%。



R1 成功的关键是蒸馏，这是一种使 AI 模型更有效的技术。 它的工作原理是让一个更大的模型来辅导一个更小的模型：你用很多例子运行教师模型并记录答案，并奖励学生模型，因为它尽可能地复制这些答案，以便它获得教师知识的压缩版本。 **—Caiwei Chen**



#### **10. 阿谀奉承 (Sycophancy)**



由于世界各地的人们花费越来越多的时间与 ChatGPT 等聊天机器人互动，聊天机器人制造商正在努力找出模型应该采用的语气和“个性”。 早在 4 月，OpenAI 就承认它在有用和谄媚之间没有取得正确的平衡，称一项新的更新使 GPT-4o 变得过于阿谀奉承。 让它巴结你不仅令人恼火，而且会通过强化用户不正确的信念和传播虚假信息来误导用户。 因此，请记住，对于 LLM 产生的一切——是的，一切——都要谨慎。 **—Rhiannon Williams**



#### **11. 垃圾 (Slop)**



如果有一个与 AI 相关的术语完全逃脱了书呆子们的包围圈并进入了公众意识，那就是“垃圾”。 这个词本身很古老（想想猪饲料），但“垃圾”现在通常用于指代 AI 生成的低成本、大规模生产的内容，通常针对在线流量进行了优化。 很多人甚至用它作为任何 AI 生成内容的简写。 在过去的一年中，它让人感觉不可避免：我们一直沉浸在其中，从虚假的传记到虾耶稣的图像，再到超现实的人类-动物混合视频。



但人们也从中获得乐趣。 这个术语的讽刺灵活性使其易于互联网用户将其作为后缀贴在各种单词上，以描述任何缺乏实质内容且荒谬地平庸的内容：想想“工作垃圾”或“朋友垃圾”。 随着炒作周期的重置，“垃圾”标志着一场关于我们信任什么、我们重视什么作为创意劳动以及被为参与而非表达而制作的东西包围意味着什么的文化清算。 **—Caiwei Chen**



#### **12. 物理智能 (Physical intelligence)**



你是否看到了今年早些时候那个令人着迷的视频，视频中一个类人机器人正在一个阴郁、灰度厨房里收拾碗碟？ 这就体现了物理智能的概念：AI 的进步可以帮助机器人更好地在物理世界中移动。 



确实，机器人学习新任务的速度比以往任何时候都快，从手术室到仓库。 自动驾驶汽车公司也看到了它们模拟道路的方式有所改进。 也就是说，对 AI 是否彻底改变了这一领域持怀疑态度仍然是明智之举。 例如，考虑到许多被宣传为你家里的管家机器人，由于菲律宾的远程操作员，它们完成了大部分任务。



物理智能的未来也肯定会很奇怪。 大型语言模型在文本上进行训练，而文本在互联网上比比皆是，但机器人更多地从人们做事视频中学习。 这就是为什么机器人公司 Figure 在 9 月份建议向人们付费，让他们在自己的公寓里录制自己做家务的视频。 你会报名吗？ **—James O’Donnell**



#### **13. 合理使用 (Fair use)**



AI 模型通过吞噬互联网上的数百万个单词和图像进行训练，包括艺术家和作家的受版权保护的作品。 AI 公司认为这是“合理使用”——一项法律原则，允许你使用受版权保护的材料而无需许可，如果你将其转化为不与原始材料竞争的新事物。 法院开始介入。 6 月，Anthropic 在其 AI 模型 Claude 上训练图书库被裁定为合理使用，因为该技术具有“极强的变革性”。



同月，Meta 取得了类似的胜利，但只是因为作者无法证明该公司的文学自助餐减少了他们的收入。 随着版权之战的酝酿，一些创作者正在从中获利。 12 月，迪士尼与 OpenAI 签署了一项引人注目的协议，允许 Sora（AI 视频平台）的用户生成包含迪士尼旗下 200 多个角色的视频。 与此同时，世界各国政府正在改写内容吞噬机器的版权规则。 在受版权保护的作品上训练 AI 是否属于合理使用？ 与任何价值数十亿美元的法律问题一样，这取决于情况。 **—Michelle Kim**



#### **14. GEO**



就在几年前，整个行业都建立在帮助网站在搜索结果中排名靠前（好吧，只是在谷歌上）的基础之上。 如今，随着 AI 繁荣迫使品牌和企业争先恐后地最大限度地提高它们在 AI 中的知名度，搜索引擎优化 (SEO) 正在让位于 GEO（生成引擎优化），无论是在 AI 增强的搜索结果（如谷歌的 AI 概览）中，还是在 LLM 的回应中。 难怪他们会惊慌失措。 我们已经知道，新闻公司已经经历了搜索驱动的 Web 流量的巨大下降，AI 公司正在寻找在他们的平台上直接切断中间商并允许用户访问网站的方法。 是时候适应或死亡了。 **—Rhiannon Williams**"

---
[原文链接](https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/)
